{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Boris1001/Microsleep_yawning/blob/main/Microsleep_yawning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KxgtLXyHwlR",
        "outputId": "7d9bd58f-0c76-4fd3-980c-84d286a0c15c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WncuVxHYHks1"
      },
      "source": [
        "# Библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftxT7c3BHqzx"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial import distance as dist\n",
        "import numpy as np\n",
        "import dlib\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import time\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from imutils.video import FileVideoStream\n",
        "from imutils.video import VideoStream\n",
        "from imutils import face_utils\n",
        "import argparse\n",
        "import imutils\n",
        "import os\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBk6bciCYv4-"
      },
      "outputs": [],
      "source": [
        "detector = dlib.get_frontal_face_detector()                                     # загружем детектор\n",
        "\n",
        "# скачать shape_predictor_68_face_landmarks.dat (файл с весами)  можно здесь : 'https://drive.google.com/file/d/1-EblxJHiWImbDlMw5hxYR8oi40X9FxVS/view?usp=share_link'\n",
        "\n",
        "weights = '/content/drive/MyDrive/Стажировка КАМАЗ/Dlib/shape_predictor_68_face_landmarks.dat'   # путь к перварительно скаченному файлу с весами\n",
        "\n",
        "predictor = dlib.shape_predictor(weights)                                        # загружаем предиктор\n",
        "\n",
        "# указываем путь к папке с фото\n",
        "path = '/content/drive/MyDrive/Стажировка КАМАЗ/cropped_photos/head/'\n",
        "\n",
        "# Устанавливанием размер обрабатывааемого изображения\n",
        "width = 600 # влияет на скорость и на точность определения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLeFktuCI-IG"
      },
      "source": [
        "# Данные"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyXwm0dXHurv"
      },
      "source": [
        "# Микросон"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1cuIj1reddJ"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/Стажировка КАМАЗ/cropped_photos/head/'           # указываем путь к папке с фото\n",
        "weights = '/content/drive/MyDrive/Стажировка КАМАЗ/Dlib/shape_predictor_68_face_landmarks.dat'   # путь к перварительно скаченному файлу с весами"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlK9zdpUzyYp"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "\n",
        "path     - путь к папке с фото\n",
        "weights  - путь к перварительно скаченному файлу с весами\n",
        "start    - первое фото в интрвале\n",
        "finish   - последнее фото в интрвале\n",
        "width    - размер фото\n",
        "'''\n",
        "\n",
        "def microsleep(path, weights, start= 0, finish = -1, width= 400):\n",
        "\n",
        "# определяем переменные\n",
        "\n",
        "    EYE_AR_THRESH = 0.3          # Соотношение глаз\n",
        "    EYE_AR_CONSEC_FRAMES = 3     # Порог мигания\n",
        "\n",
        "    COUNTER_flashing = 0         # Счетчик кадров для мигания\n",
        "    COUNTER = 0                  # Счетчик кадров\n",
        "\n",
        "    TOTAL = 0                    # Счетчик количества миганий\n",
        "\n",
        "\n",
        "    filenames = []                                                              # определяем список с именами файлов в порядке возрастания\n",
        "    result = {}                                                                 # определяем словарь для записи результата в формате: 'имя файла':  'результат определения лица'\n",
        "\n",
        "    detector = dlib.get_frontal_face_detector()                                 # загружем детектор\n",
        "    predictor = dlib.shape_predictor(weights)                                   # загружаем предиктор\n",
        "\n",
        "    filenames = sorted(os.listdir(path), key= lambda x: int(str(re.search('\\d+',x).group(0))))   # получаем список с именами файлов в порядке возрастания\n",
        "\n",
        "# Получаем указатель на признаки лица левого и правого глаза и рта\n",
        "\n",
        "    (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
        "    (rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
        "\n",
        "# идентифицируем точки\n",
        "\n",
        "    FACIAL_LANDMARKS_68_IDXS = dict([\n",
        "      (\"mouth\", (48, 68)),\n",
        "      (\"right_eyebrow\", (17, 22)),\n",
        "      (\"left_eyebrow\", (22, 27)),\n",
        "      (\"right_eye\", (36, 42)),\n",
        "      (\"left_eye\", (42, 48)),\n",
        "      (\"nose\", (27, 36)),\n",
        "      (\"jaw\", (0, 17))\n",
        "    ])\n",
        "\n",
        "# функция определения открытого глаза\n",
        "\n",
        "    def eye_aspect_ratio(eye):\n",
        "# Рассчитать расстояние по вертикали\n",
        "        A = dist.euclidean(eye[1], eye[5])\n",
        "        B = dist.euclidean(eye[2], eye[4])\n",
        "# Рассчитать расстояние по горизонтали\n",
        "        C = dist.euclidean(eye[0], eye[3])\n",
        "        ear = (A + B) / (2.0 * C)\n",
        "        return ear\n",
        "\n",
        "# функция получения координат\n",
        "    def shape_to_np(shape, dtype=\"int\"):\n",
        "# Создать 68 * 2\n",
        "      coords = np.zeros((shape.num_parts, 2), dtype=dtype)\n",
        "# Обойти каждую ключевую точку\n",
        "# Получить координаты\n",
        "      for i in range(0, shape.num_parts):\n",
        "          coords[i] = (shape.part(i).x, shape.part(i).y)\n",
        "      return coords\n",
        "\n",
        "\n",
        "#    for name in filenames:                                                     # проходим по всмему списку в порядке возрастания\n",
        "    for name in filenames[start:finish]:                                        # выбираем диапазон\n",
        "\n",
        "      data = cv2.imread(path + name)                                               # считываем изображения по порядку\n",
        "      if data is None:\n",
        "          break\n",
        "#  resize и переводим в серый\n",
        "      (h, w) = data.shape[:2]\n",
        "\n",
        "      r = width / float(w)\n",
        "      dim = (width, int(h * r))\n",
        "      data = cv2.resize(data, dim, interpolation=cv2.INTER_AREA)\n",
        "      gray = cv2.cvtColor(data, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "      rects = detector(gray, 0)                                                 # Используем детектор для определения положения лица\n",
        "\n",
        "# Зацикливание информации о положении лица и использование предиктора для получения информации о положении лица\n",
        "      for rect in rects:\n",
        "        shape = predictor(gray, rect)                                           # Используем предиктор для определения положения лица\n",
        "\n",
        "        shape = face_utils.shape_to_np(shape)                                   # Преобразование информации о чертах лица в формат массива\n",
        "\n",
        "        leftEye = shape[lStart:lEnd]                                            # Извлекаем координаты левого и правого глаза\n",
        "        rightEye = shape[rStart:rEnd]\n",
        "\n",
        "# Конструктор вычисляет значение EAR для левого и правого глаза, используя среднее значение в качестве окончательного EAR\n",
        "        leftEAR = eye_aspect_ratio(leftEye)\n",
        "        rightEAR = eye_aspect_ratio(rightEye)\n",
        "        ear = (leftEAR + rightEAR) / 2.0\n",
        "\n",
        "# ---------------------------------------------------------------------------------------------------------\n",
        "#    смотрим что получилось, в итоговую модель вставлять не нужно\n",
        "# Изображаем позицию глаз и рта\n",
        "\n",
        "        leftEyeHull = cv2.convexHull(leftEye)\n",
        "        rightEyeHull = cv2.convexHull(rightEye)\n",
        "        cv2.drawContours(data, [leftEyeHull], -1, (0, 255, 0), 1)\n",
        "        cv2.drawContours(data, [rightEyeHull], -1, (0, 255, 0), 1)\n",
        "\n",
        "        # Помечаем контур лица прямоугольной рамкой\n",
        "        left = rect.left()\n",
        "        top = rect.top()\n",
        "        right = rect.right()\n",
        "        bottom = rect.bottom()\n",
        "        cv2.rectangle(data, (left, top), (right, bottom), (0, 255, 0), 3)\n",
        " # ---------------------------------------------------------------------------------------------------------\n",
        "        '''\n",
        "                         Делаем оценку для левого и правого глаза отдельно в качестве окончательной оценки. Если она меньше порога, добавляем 1, если она меньше порога в течение трех последовательных раз, это означает, что было выполнено одно событие мигания\n",
        "        '''\n",
        "        # Цикл, если условие выполнено, количество миганий +1\n",
        "        if ear < EYE_AR_THRESH:                                                 # проверяем соотношение глаз\n",
        "            COUNTER += 1\n",
        "\n",
        "        else:\n",
        "            # Если все три раза подряд меньше порога, это означает мигание\n",
        "            if COUNTER >= EYE_AR_CONSEC_FRAMES:                                 # Сравниваем с установленным порогом\n",
        "                TOTAL += 1\n",
        "\n",
        "            COUNTER = 0                                                         # Сброс счетчика кадров глаз\n",
        "\n",
        " # ---------------------------------------------------------------------------------------------------------\n",
        "#    смотрим что получилось, в итоговую модель вставлять не нужно\n",
        "        # Отображаем количества миганий\n",
        "        cv2.putText(data, \"Faces: {}\".format(len(rects)), (10, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "        cv2.putText(data, \"Blinks: {}\".format(TOTAL), (150, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "        cv2.putText(data, \"COUNTER: {}\".format(COUNTER), (300, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "        cv2.putText(data, \"EAR: {:.2f}\".format(ear), (450, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "\n",
        "      cv2_imshow(data)\n",
        "\n",
        "\n",
        "#        break\n",
        "\n",
        " # cv2.destroyAllWindows()\n",
        " # ---------------------------------------------------------------------------------------------------------\n",
        "\n",
        "#    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PJBe1GDr2JF6"
      },
      "outputs": [],
      "source": [
        "microsleep(path, weights, 50, 60, 400)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXMWzBu0zzhV"
      },
      "source": [
        "# Утомлённость"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3z82BF9rxn_d"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "path     - путь к папке с фото\n",
        "weights  - путь к перварительно скаченному файлу с весами\n",
        "start    - первое фото в интрвале\n",
        "finish   - последнее фото в интрвале\n",
        "width    - размер фото\n",
        "'''\n",
        "\n",
        "def microsleep(path, weights, start= 0, finish = -1, width= 400):\n",
        "\n",
        "# определяем переменные\n",
        "\n",
        "    EYE_AR_THRESH = 0.3          # Соотношение глаз\n",
        "    EYE_AR_CONSEC_FRAMES = 3     # Порог мигания\n",
        "\n",
        "    MAR_THRESH = 0.5             # Соотношение рта (зевание)\n",
        "    MOUTH_AR_CONSEC_FRAMES = 3   # Порог зевания\n",
        "\n",
        "    COUNTER = 0                  # Счетчик кадров для мигания\n",
        "    TOTAL = 0                    # Счетчик количества миганий\n",
        "\n",
        "    mCOUNTER = 0                 # Счетчик кадров для зевания\n",
        "    mTOTAL = 0                   # Счетчик общего количества зевания\n",
        "\n",
        "    filenames = []                                                              # определяем список с именами файлов в порядке возрастания\n",
        "    result = {}                                                                 # определяем словарь для записи результата в формате: 'имя файла':  'результат определения лица'\n",
        "\n",
        "    detector = dlib.get_frontal_face_detector()                                 # загружем детектор\n",
        "    predictor = dlib.shape_predictor(weights)                                   # загружаем предиктор\n",
        "\n",
        "    filenames = sorted(os.listdir(path), key= lambda x: int(str(re.search('\\d+',x).group(0))))   # получаем список с именами файлов в порядке возрастания\n",
        "\n",
        "\n",
        "# Получаем указатель на признаки лица левого и правого глаза и рта\n",
        "\n",
        "    (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
        "    (rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
        "    (mStart, mEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]\n",
        "\n",
        "# идентифицируем точки\n",
        "\n",
        "    FACIAL_LANDMARKS_68_IDXS = dict([\n",
        "      (\"mouth\", (48, 68)),\n",
        "      (\"right_eyebrow\", (17, 22)),\n",
        "      (\"left_eyebrow\", (22, 27)),\n",
        "      (\"right_eye\", (36, 42)),\n",
        "      (\"left_eye\", (42, 48)),\n",
        "      (\"nose\", (27, 36)),\n",
        "      (\"jaw\", (0, 17))\n",
        "    ])\n",
        "\n",
        "# функция определения открытого глаза\n",
        "\n",
        "    def eye_aspect_ratio(eye):\n",
        "# Рассчитать расстояние по вертикали\n",
        "        A = dist.euclidean(eye[1], eye[5])\n",
        "        B = dist.euclidean(eye[2], eye[4])\n",
        "# Рассчитать расстояние по горизонтали\n",
        "        C = dist.euclidean(eye[0], eye[3])\n",
        "        ear = (A + B) / (2.0 * C)\n",
        "        return ear\n",
        "\n",
        "# функция получения координат\n",
        "    def shape_to_np(shape, dtype=\"int\"):\n",
        "# Создать 68 * 2\n",
        "      coords = np.zeros((shape.num_parts, 2), dtype=dtype)\n",
        "# Обойти каждую ключевую точку\n",
        "# Получить координаты\n",
        "      for i in range(0, shape.num_parts):\n",
        "          coords[i] = (shape.part(i).x, shape.part(i).y)\n",
        "      return coords\n",
        "\n",
        "\n",
        "#    for name in filenames:                                                     # проходим по всмему списку в порядке возрастания\n",
        "    for name in filenames[start:finish]:                                        # выбираем диапазон\n",
        "\n",
        "      data = cv2.imread(path + p)                                               # считываем изображения по порядку\n",
        "      if data is None:\n",
        "          break\n",
        "#  resize и переводим в серый\n",
        "      (h, w) = frame.shape[:2]\n",
        "\n",
        "      r = width / float(w)\n",
        "      dim = (width, int(h * r))\n",
        "      data = cv2.resize(data, dim, interpolation=cv2.INTER_AREA)\n",
        "      gray = cv2.cvtColor(data, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "      rects = detector(gray, 0)                                                 # Используем детектор для определения положения лица\n",
        "\n",
        "# Зацикливание информации о положении лица и использование предиктора для получения информации о положении лица\n",
        "    for rect in rects:\n",
        "        shape = predictor(gray, rect)                                           # Используем предиктор для определения положения лица\n",
        "\n",
        "        shape = face_utils.shape_to_np(shape)                                   # Преобразование информации о чертах лица в формат массива\n",
        "\n",
        "        leftEye = shape[lStart:lEnd]                                            # Извлекаем координаты левого и правого глаза\n",
        "        rightEye = shape[rStart:rEnd]\n",
        "\n",
        "        mouth = shape[mStart:mEnd]                                              # Координаты рта\n",
        "\n",
        "# Конструктор вычисляет значение EAR для левого и правого глаза, используя среднее значение в качестве окончательного EAR\n",
        "        leftEAR = eye_aspect_ratio(leftEye)\n",
        "        rightEAR = eye_aspect_ratio(rightEye)\n",
        "        ear = (leftEAR + rightEAR) / 2.0\n",
        "\n",
        "        mar = mouth_aspect_ratio(mouth)                                         # Определяем зевок\n",
        "# ---------------------------------------------------------------------------------------------------------\n",
        "#    смотрим что получилось, в итоговую модель вставлять не нужно\n",
        "# Изображаем позицию глаз и рта\n",
        "        leftEyeHull = cv2.convexHull(leftEye)\n",
        "        rightEyeHull = cv2.convexHull(rightEye)\n",
        "        cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
        "        cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
        "        mouthHull = cv2.convexHull(mouth)\n",
        "        cv2.drawContours(frame, [mouthHull], -1, (0, 255, 0), 1)\n",
        "\n",
        "        # Помечаем контур лица прямоугольной рамкой\n",
        "        left = rect.left()\n",
        "        top = rect.top()\n",
        "        right = rect.right()\n",
        "        bottom = rect.bottom()\n",
        "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 3)\n",
        " # ---------------------------------------------------------------------------------------------------------\n",
        "        '''\n",
        "                         Делаем оценку для левого и правого глаза отдельно в качестве окончательной оценки. Если она меньше порога, добавляем 1, если она меньше порога в течение трех последовательных раз, это означает, что было выполнено одно событие мигания\n",
        "        '''\n",
        "        # Цикл, если условие выполнено, количество миганий +1\n",
        "        if ear < EYE_AR_THRESH:                        # проверяем соотношение глаз\n",
        "            COUNTER += 1\n",
        "\n",
        "        else:\n",
        "            # Если все три раза подряд меньше порога, это означает мигание\n",
        "            if COUNTER >= EYE_AR_CONSEC_FRAMES:# Сравниваем с установленным порогом\n",
        "                TOTAL += 1\n",
        "\n",
        "            COUNTER = 0                                # Сброс счетчика кадров глаз\n",
        "\n",
        " # ---------------------------------------------------------------------------------------------------------\n",
        "#    смотрим что получилось, в итоговую модель вставлять не нужно\n",
        "        # Отображаем количества миганий\n",
        "        cv2.putText(frame, \"Faces: {}\".format(len(rects)), (10, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "        cv2.putText(frame, \"Blinks: {}\".format(TOTAL), (150, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "        cv2.putText(frame, \"COUNTER: {}\".format(COUNTER), (300, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "        cv2.putText(frame, \"EAR: {:.2f}\".format(ear), (450, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "  # ---------------------------------------------------------------------------------------------------------\n",
        "\n",
        "        '''\n",
        "                         Делаем оценку открытого рта, если она меньше порога, добаляем 1, если он меньше порога три раза подряд, это означает, что зевок сделан, и тот же зевок составляет около 3 кадров.\n",
        "        '''\n",
        "\n",
        "        # Цикл, если условие выполнено, количество зеваний +1\n",
        "        if mar > MAR_THRESH:                           # проверяем соотношение рта (определяем зевание)\n",
        "            mCOUNTER += 1\n",
        "            cv2.putText(frame, \"Yawning!\", (10, 60),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "        else:\n",
        "            # Если оно меньше порога 3 раза подряд, это означает зевок\n",
        "            if mCOUNTER >= MOUTH_AR_CONSEC_FRAMES:     # Сравниваем с установленным порогом\n",
        "                mTOTAL += 1\n",
        "            # Сброс счетчика кадров рта\n",
        "            mCOUNTER = 0\n",
        "\n",
        "# ---------------------------------------------------------------------------------------------------------\n",
        "#    смотрим что получилось, в итоговую модель вставлять не нужно\n",
        "        cv2.putText(frame, \"Yawning: {}\".format(mTOTAL), (150, 60),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "        cv2.putText(frame, \"mCOUNTER: {}\".format(mCOUNTER), (300, 60),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "        cv2.putText(frame, \"MAR: {:.2f}\".format(mar), (480, 60),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "\n",
        "        # Операция рисования, 68 идентификация характерных точек\n",
        "        for (x, y) in shape:\n",
        "            cv2.circle(frame, (x, y), 1, (0, 0, 255), -1)\n",
        "# ---------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "    # Определяем усталость\n",
        "    if TOTAL >= 50 or mTOTAL>=15:\n",
        " # ---------------------------------------------------------------------------------------------------------\n",
        "#    смотрим что получилось, в итоговую модель вставлять не нужно\n",
        "        cv2.putText(frame, \"SLEEP!!!\", (100, 200),cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
        "\n",
        "    # Нажмите q для выхода\n",
        "    # cv2.putText(frame, \"Press 'q': Quit\", (20, 500),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (84, 255, 159), 2)\n",
        "    # Показ окна с помощью opencv\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "\n",
        "    # if the `q` key was pressed, break from the loop\n",
        "#   if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "#        break\n",
        "\n",
        " # cv2.destroyAllWindows()\n",
        " # ---------------------------------------------------------------------------------------------------------\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1pUFd7EGYkT"
      },
      "outputs": [],
      "source": [
        "def microsleep(path, width):\n",
        "\n",
        "  EYE_AR_THRESH = 0.3          # Соотношение глаз\n",
        "  EYE_AR_CONSEC_FRAMES = 3     # Порог мигания\n",
        "\n",
        "  MAR_THRESH = 0.5             # Соотношение рта (зевание)\n",
        "  MOUTH_AR_CONSEC_FRAMES = 3   # Порог зевания\n",
        "\n",
        "  COUNTER = 0                  # Счетчик кадров для мигания\n",
        "  TOTAL = 0                    # Счетчик количества миганий\n",
        "\n",
        "  mCOUNTER = 0                 # Счетчик кадров для зевания\n",
        "  mTOTAL = 0                   # Счетчик общего количества зевания\n",
        "\n",
        "\n",
        "  # Получаем указатель на признаки лица левого и правого глаза и рта\n",
        "  (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
        "  (rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
        "  (mStart, mEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]\n",
        "\n",
        "  # идентифицируем точки\n",
        "  FACIAL_LANDMARKS_68_IDXS = dict([\n",
        "    (\"mouth\", (48, 68)),\n",
        "    (\"right_eyebrow\", (17, 22)),\n",
        "    (\"left_eyebrow\", (22, 27)),\n",
        "    (\"right_eye\", (36, 42)),\n",
        "    (\"left_eye\", (42, 48)),\n",
        "    (\"nose\", (27, 36)),\n",
        "    (\"jaw\", (0, 17))\n",
        "  ])\n",
        "\n",
        "  # функция определения открытого глаза\n",
        "  def eye_aspect_ratio(eye):\n",
        "    # Рассчитать расстояние по вертикали\n",
        "    A = dist.euclidean(eye[1], eye[5])\n",
        "    B = dist.euclidean(eye[2], eye[4])\n",
        "    # Рассчитать расстояние по горизонтали\n",
        "    C = dist.euclidean(eye[0], eye[3])\n",
        "    ear = (A + B) / (2.0 * C)\n",
        "    return ear\n",
        "  # функция получения координат\n",
        "  def shape_to_np(shape, dtype=\"int\"):\n",
        "    # Создать 68 * 2\n",
        "    coords = np.zeros((shape.num_parts, 2), dtype=dtype)\n",
        "    # Обойти каждую ключевую точку\n",
        "    # Получить координаты\n",
        "    for i in range(0, shape.num_parts):\n",
        "        coords[i] = (shape.part(i).x, shape.part(i).y)\n",
        "    return coords\n",
        "\n",
        "\n",
        "  for p in os.listdir(path):\n",
        "    startTime = time.time()\n",
        "    frame = cv2.imread(path + p)\n",
        "    if frame is None:\n",
        "        break\n",
        "\n",
        "    (h, w) = frame.shape[:2]\n",
        "\n",
        "    r = width / float(w)\n",
        "    dim = (width, int(h * r))\n",
        "    frame = cv2.resize(frame, dim, interpolation=cv2.INTER_AREA)\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Используем детектор (серый, 0) для определения положения лица\n",
        "    rects = detector(gray, 0)\n",
        "\n",
        "    # Зацикливание информации о положении лица и использование предиктора (серый, прямоугольный) для получения информации о положении лица\n",
        "    for rect in rects:\n",
        "        shape = predictor(gray, rect)\n",
        "\n",
        "        # Преобразование информации о чертах лица в формат массива\n",
        "        shape = face_utils.shape_to_np(shape)\n",
        "\n",
        "        # Извлекаем координаты левого и правого глаза\n",
        "        leftEye = shape[lStart:lEnd]\n",
        "        rightEye = shape[rStart:rEnd]\n",
        "\n",
        "        # Координаты рта\n",
        "        mouth = shape[mStart:mEnd]\n",
        "\n",
        "        # Конструктор вычисляет значение EAR для левого и правого глаз, используя среднее значение в качестве окончательного EAR\n",
        "        leftEAR = eye_aspect_ratio(leftEye)\n",
        "        rightEAR = eye_aspect_ratio(rightEye)\n",
        "        ear = (leftEAR + rightEAR) / 2.0\n",
        "\n",
        "        # Определяем зевок\n",
        "        mar = mouth_aspect_ratio(mouth)\n",
        "\n",
        "        # Изображаем позицию глаз и рта\n",
        "\n",
        "        leftEyeHull = cv2.convexHull(leftEye)\n",
        "        rightEyeHull = cv2.convexHull(rightEye)\n",
        "        cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
        "        cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
        "        mouthHull = cv2.convexHull(mouth)\n",
        "        cv2.drawContours(frame, [mouthHull], -1, (0, 255, 0), 1)\n",
        "\n",
        "        # Помечаем контур лица прямоугольной рамкой\n",
        "        left = rect.left()\n",
        "        top = rect.top()\n",
        "        right = rect.right()\n",
        "        bottom = rect.bottom()\n",
        "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 3)\n",
        "\n",
        "        '''\n",
        "                         Делаем оценку для левого и правого глаза отдельно в качестве окончательной оценки. Если она меньше порога, добавляем 1, если она меньше порога в течение трех последовательных раз, это означает, что было выполнено одно событие мигания\n",
        "        '''\n",
        "        # Цикл, если условие выполнено, количество миганий +1\n",
        "        if ear < EYE_AR_THRESH:                        # проверяем соотношение глаз\n",
        "            COUNTER += 1\n",
        "\n",
        "        else:\n",
        "            # Если все три раза подряд меньше порога, это означает мигание\n",
        "            if COUNTER >= EYE_AR_CONSEC_FRAMES:# Сравниваем с установленным порогом\n",
        "                TOTAL += 1\n",
        "\n",
        "            COUNTER = 0                                # Сброс счетчика кадров глаз\n",
        "\n",
        "        # Отображаем количества миганий\n",
        "        cv2.putText(frame, \"Faces: {}\".format(len(rects)), (10, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "        cv2.putText(frame, \"Blinks: {}\".format(TOTAL), (150, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "        cv2.putText(frame, \"COUNTER: {}\".format(COUNTER), (300, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "        cv2.putText(frame, \"EAR: {:.2f}\".format(ear), (450, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "\n",
        "        '''\n",
        "                         Делаем оценку открытого рта, если она меньше порога, добаляем 1, если он меньше порога три раза подряд, это означает, что зевок сделан, и тот же зевок составляет около 3 кадров.\n",
        "        '''\n",
        "        # Цикл, если условие выполнено, количество зеваний +1\n",
        "        if mar > MAR_THRESH:                           # проверяем соотношение рта (определяем зевание)\n",
        "            mCOUNTER += 1\n",
        "            cv2.putText(frame, \"Yawning!\", (10, 60),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "        else:\n",
        "            # Если оно меньше порога 3 раза подряд, это означает зевок\n",
        "            if mCOUNTER >= MOUTH_AR_CONSEC_FRAMES:     # Сравниваем с установленным порогом\n",
        "                mTOTAL += 1\n",
        "            # Сброс счетчика кадров рта\n",
        "            mCOUNTER = 0\n",
        "        cv2.putText(frame, \"Yawning: {}\".format(mTOTAL), (150, 60),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "        cv2.putText(frame, \"mCOUNTER: {}\".format(mCOUNTER), (300, 60),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "        cv2.putText(frame, \"MAR: {:.2f}\".format(mar), (480, 60),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "\n",
        "        # Операция рисования, 68 идентификация характерных точек\n",
        "        for (x, y) in shape:\n",
        "            cv2.circle(frame, (x, y), 1, (0, 0, 255), -1)\n",
        "\n",
        "\n",
        "    # Определяем усталость\n",
        "    if TOTAL >= 50 or mTOTAL>=15:\n",
        "\n",
        "        cv2.putText(frame, \"SLEEP!!!\", (100, 200),cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
        "\n",
        "    # Нажмите q для выхода\n",
        "    # cv2.putText(frame, \"Press 'q': Quit\", (20, 500),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (84, 255, 159), 2)\n",
        "    # Показ окна с помощью opencv\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "    # if the `q` key was pressed, break from the loop\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "  cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh5JUbrLh6XD"
      },
      "source": [
        "# Отвлечение взгляда"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OV-PntiqWzWb"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/Стажировка КАМАЗ/cropped_photos/head/'           # путь к папке с фото"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lG5lEHnVnj4"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "path   - путь к папке с фото\n",
        "start  - первое фото в интрвале\n",
        "finish - последнее фото в интрвале\n",
        "width  - размер фото\n",
        "'''\n",
        "\n",
        "def distraction(path, start= 0, finish = -1, width= 400):\n",
        "\n",
        "    filenames = []                                                              # определяем список с именами файлов в порядке возрастания\n",
        "    result = {}                                                                 # определяем словарь для записи результата в формате: 'имя файла':  'результат определения лица'\n",
        "\n",
        "    detector = dlib.get_frontal_face_detector()                                 # загружем детектор\n",
        "\n",
        "    filenames = sorted(os.listdir(path), key= lambda x: int(str(re.search('\\d+',x).group(0))))   # получаем список с именами файлов в порядке возрастания\n",
        "\n",
        "\n",
        "#    for name in filenames:                                                     # проходим по всмему списку в порядке возрастания\n",
        "    for name in filenames[start:finish]:                                        # выбираем диапазон\n",
        "\n",
        "        data = cv2.imread(path + name)                                          # считываем изображения по порядку\n",
        "\n",
        "        if data is None:\n",
        "            break\n",
        "\n",
        "        (h, w) = data.shape[:2]\n",
        "        r = width / float(w)\n",
        "        dim = (width, int(h * r))\n",
        "        data = cv2.resize(data, dim, interpolation=cv2.INTER_AREA)              # меняем размер фото\n",
        "\n",
        "        face = detector(data,0)                                                 # получаем координаты лица\n",
        "\n",
        "        if face:\n",
        "          result[name] = result.get(name, True)                                 # если координаты есть - добавляем по ключу(имя изображение) значение (True)\n",
        "        else:\n",
        "          result[name] = result.get(name, False)                                # если координат нет - добавляем по ключу(имя изображение) значение (False)\n",
        "\n",
        "# ---------------------------------------------------------------------------------------------------------\n",
        "#    смотрим что получилось, в итоговую модель вставлять не нужно\n",
        "\n",
        "        for rect in face:\n",
        "          left = rect.left()\n",
        "          top = rect.top()\n",
        "          right = rect.right()\n",
        "          bottom = rect.bottom()\n",
        "          cv2.rectangle(data, (left, top), (right, bottom), (0, 255, 0), 3)\n",
        "\n",
        "        cv2_imshow(data)\n",
        "\n",
        "# ---------------------------------------------------------------------------------------------------------\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbKu_UMKbTKV"
      },
      "outputs": [],
      "source": [
        "res = distraction(path, 135, 170, 400)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "pXMWzBu0zzhV"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyMGZNx8P2xfh4zpDWztj+IP",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}